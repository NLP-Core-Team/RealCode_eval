defaults:
    - task: SG
    
job:
    config:
        override_dirname:
            exclude_keys: 
                - dataset_root
                - dataset_meta_file
                - generations_save_path
                - working_dir
                - metrics_save_path
                - use_cached_generation
                
do_eval: True
do_generation: True
# random seed
seed: 42
                
 # dataset paths
dataset_root: '${hydra:runtime.cwd}/data/realcode_v3'
limit: 10_000
                
# model related values that must be overriden, see for example config/model/codellama.yaml
model_path: 
model_short_name: 
size: 
lm_prefix_tokens: ""
prefix_tokens: ""
middle_tokens: ""
suffix_tokens: ""
max_context_length: 100000
left_context_ratio: 1
                
# 'lm' or 'infill', whether to use right context in generation
generator_mode: infill
# number of samples to generate per task
num_samples: 1
# datatype to use (fp32, fp16 or bf16)
dtype: bf16
# params to be passed to .generate method
generation_params:
    temperature: 0.2
    do_sample: True
    top_p: 1.0
    max_new_tokens: 1024

# NOT USED anymore
# eos_sequences: ["\\sclass\\s", "\\sdef\\s", "^def\\s", "^class\\s", "^if\\s", "@", "^#", "<|endoftext|>"]
#     # fix tokenization issue with llamatokenizer, set to 1 if the first generated line is underidented
# tokenizer_fix: 0 

# path where generations are stored
generations_save_path: "${hydra:runtime.cwd}/data/generations/${hydra:job.override_dirname}.json"
# whether to reuse saved generations
use_cached_generations: True
# list of Pass@k (https://arxiv.org/abs/2107.03374) metrics. [1,3] means Pass@1 and Pass@3 will be calculated
pass_k_list: [1]
# evaluation n_jobs
njobs: 8
working_dir: "${hydra:runtime.cwd}/workdir/${hydra:job.override_dirname}"
metrics_save_path: "${hydra:runtime.cwd}/results/${hydra:job.override_dirname}.json"